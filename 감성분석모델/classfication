from transformers import BertModel, BertTokenizerFast, Trainer, TrainingArguments
import torch
import nltk

model = BertModel.from_pretrained('bert-large-uncased-whole-word-masking', output_hidden_states = True)
tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased-whole-word-masking')
from transformers import BertModel, BertTokenizerFast, Trainer, TrainingArguments
import torch
import nltk

model = BertModel.from_pretrained('bert-large-uncased-whole-word-masking', output_hidden_states = True)
tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased-whole-word-masking')
